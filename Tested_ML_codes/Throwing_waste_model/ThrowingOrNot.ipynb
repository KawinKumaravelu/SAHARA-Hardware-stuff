{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea482098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python, OpenCV, NumPy, TF versions:\n",
      "cv2: 4.8.0 numpy: 1.24.3 tf: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "# Cell 1\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"Python, OpenCV, NumPy, TF versions:\")\n",
    "print(\"cv2:\", cv2.__version__, \"numpy:\", np.__version__, \"tf:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fcfaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "# We're assuming this notebook is inside Tmodel and the two class folders exist here.\n",
    "DATA_DIR = '.'  # Tmodel (current directory)\n",
    "CLASS_NAMES = [\"NOT_THROWING_WASTE\", \"THROWING_WASTE\"]  # EXACT folder names\n",
    "IMG_SIZE = 64          # image height/width\n",
    "FRAME_SKIP = 5         # take every 5th frame from each video\n",
    "TEST_SIZE = 0.20       # fraction for test set\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "OUTPUT_MODEL = \"throwing_waste_model.h5\"\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cd54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "def extract_frames_from_video(video_path, frame_skip=FRAME_SKIP, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Read video and extract frames (every frame_skip-th frame), convert BGR->RGB,\n",
    "    resize to img_size x img_size and return list of frames (RGB, 0..255).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open:\", video_path)\n",
    "        return frames\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "        if frame_idx % frame_skip == 0:\n",
    "            # convert to RGB (so visuals with matplotlib look right) and resize\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_resized = cv2.resize(frame_rgb, (img_size, img_size))\n",
    "            frames.append(frame_resized)\n",
    "    cap.release()\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777dc6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: NOT_THROWING_WASTE\n",
      "Processing class: THROWING_WASTE\n",
      "Dataset prepared. Data shape: (4164, 64, 64, 3) Labels shape: (4164,)\n",
      "Counts: {'NOT_THROWING_WASTE': 2657, 'THROWING_WASTE': 1507}\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# iterate classes and videos\n",
    "for class_index, class_name in enumerate(CLASS_NAMES):\n",
    "    folder = os.path.join(DATA_DIR, class_name)\n",
    "    if not os.path.isdir(folder):\n",
    "        print(\"WARNING: folder not found:\", folder)\n",
    "        continue\n",
    "    print(\"Processing class:\", class_name)\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            continue\n",
    "        fpath = os.path.join(folder, fname)\n",
    "        frames = extract_frames_from_video(fpath)\n",
    "        if len(frames) == 0:\n",
    "            print(\"  no frames extracted from\", fname)\n",
    "            continue\n",
    "        # append each frame as a sample\n",
    "        for fr in frames:\n",
    "            data.append(fr)\n",
    "            labels.append(class_index)\n",
    "\n",
    "# convert to numpy arrays and normalize\n",
    "data = np.array(data, dtype='float32') / 255.0   # shape: (N, H, W, 3)\n",
    "labels = np.array(labels, dtype='int32')         # shape: (N,)\n",
    "print(\"Dataset prepared. Data shape:\", data.shape, \"Labels shape:\", labels.shape)\n",
    "\n",
    "# class counts\n",
    "(unique, counts) = np.unique(labels, return_counts=True)\n",
    "print(\"Counts:\", dict(zip([CLASS_NAMES[int(u)] for u in unique], counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5407de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3331, 64, 64, 3) (3331, 2)\n",
      "Test shape: (833, 64, 64, 3) (833, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5\n",
    "# Shuffle\n",
    "data, labels = shuffle(data, labels, random_state=RANDOM_SEED)\n",
    "\n",
    "# One-hot encode\n",
    "y = to_categorical(labels, num_classes=len(CLASS_NAMES))\n",
    "\n",
    "# Train/test split (stratify to keep class ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=labels\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d131402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1048704   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1143106 (4.36 MB)\n",
      "Trainable params: 1142658 (4.36 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell 6\n",
    "def build_frame_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_frame_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=len(CLASS_NAMES))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35148ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9555\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36134, saving model to models\\throwing_waste_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\KAWIN T K\\PrOgRaMmInG\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 23s 196ms/step - loss: 0.2729 - accuracy: 0.9556 - val_loss: 29.6251 - val_accuracy: 0.3613\n",
      "Epoch 2/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9874\n",
      "Epoch 2: val_accuracy did not improve from 0.36134\n",
      "105/105 [==============================] - 20s 190ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 26.3018 - val_accuracy: 0.3613\n",
      "Epoch 3/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9904\n",
      "Epoch 3: val_accuracy improved from 0.36134 to 0.40936, saving model to models\\throwing_waste_model.h5\n",
      "105/105 [==============================] - 19s 186ms/step - loss: 0.0500 - accuracy: 0.9904 - val_loss: 9.2938 - val_accuracy: 0.4094\n",
      "Epoch 4/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 9.9690e-04 - accuracy: 1.0000\n",
      "Epoch 4: val_accuracy improved from 0.40936 to 0.76711, saving model to models\\throwing_waste_model.h5\n",
      "105/105 [==============================] - 20s 186ms/step - loss: 9.9895e-04 - accuracy: 1.0000 - val_loss: 1.6844 - val_accuracy: 0.7671\n",
      "Epoch 5/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9988\n",
      "Epoch 5: val_accuracy improved from 0.76711 to 1.00000, saving model to models\\throwing_waste_model.h5\n",
      "105/105 [==============================] - 20s 192ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 9.0452e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 20s 192ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.5239e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 2.8499e-04 - accuracy: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 21s 195ms/step - loss: 2.8474e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9976\n",
      "Epoch 8/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 8.8244e-04 - accuracy: 0.9994\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 18s 170ms/step - loss: 8.8165e-04 - accuracy: 0.9994 - val_loss: 2.7222e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9973\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 20s 187ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0938 - val_accuracy: 0.9772\n",
      "Epoch 10/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9850\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 21s 195ms/step - loss: 0.1116 - accuracy: 0.9850 - val_loss: 3.2296 - val_accuracy: 0.8631\n",
      "Epoch 11/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9937\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 20s 191ms/step - loss: 0.0511 - accuracy: 0.9937 - val_loss: 0.9651 - val_accuracy: 0.9040\n",
      "Epoch 12/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9937\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 20s 190ms/step - loss: 0.0483 - accuracy: 0.9937 - val_loss: 0.1542 - val_accuracy: 0.9892\n",
      "Epoch 13/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9991\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 20s 188ms/step - loss: 0.0150 - accuracy: 0.9988 - val_loss: 0.0277 - val_accuracy: 0.9964\n",
      "Epoch 14/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9967\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "105/105 [==============================] - 20s 187ms/step - loss: 0.0220 - accuracy: 0.9967 - val_loss: 0.3308 - val_accuracy: 0.9748\n",
      "Epoch 15/25\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9964\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "105/105 [==============================] - 20s 189ms/step - loss: 0.0292 - accuracy: 0.9961 - val_loss: 0.2076 - val_accuracy: 0.9796\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Cell 7\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join('models', OUTPUT_MODEL),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[checkpoint, earlystop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
